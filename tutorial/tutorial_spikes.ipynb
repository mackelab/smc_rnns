{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea98285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys, os\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter, NullFormatter\n",
    "\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d5bb93",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "\n",
    "We will use the `pytorch` `Dataset` class for handling the data.\n",
    "\n",
    "Here we wil load some data of 40 artificial neurons that implement a noisy oscillator. This data is an array of dimensions `num_units x sequence_length`, which we use to initialise a `Basic_dataset`.\n",
    "\n",
    "If one has data with trial structure one can instead initialise the `Basic_dataset_with_trials` class using an array of dimensions `num_trials x num_units x sequence_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eb7c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vi_rnn.datasets import Basic_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5860267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_all = np.load(\"tutorial_data/spiking_data.npy\")\n",
    "\n",
    "# split into train and eval\n",
    "eval_split_ts = int(.75*data_all.shape[1])\n",
    "data_train = data_all[:,:eval_split_ts]\n",
    "data_eval = data_all[:,eval_split_ts:]\n",
    "\n",
    "\n",
    "# initialise a dataset class\n",
    "task_params = {\"name\": \"tutorial_cont\",\n",
    "               \"dur\": 100, # we will sample pseudo trials of \"dur\" timesteps during training\n",
    "               \"n_trials\": 400 # every epoch consists of 256 psuedo trials\n",
    "               }\n",
    "dataset = Basic_dataset(\n",
    "    task_params=task_params,\n",
    "    data=data_train, \n",
    "    data_eval=data_eval, \n",
    "    stim = None, # you could additionally pass input / stimuli like this\n",
    "    stim_eval = None,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7de9c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some example data\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 2))\n",
    "ax.imshow(dataset.data[:,:1000],aspect='auto',cmap=\"Grays\",vmax=2)\n",
    "ax.set_xlabel(\"timesteps\")\n",
    "ax.set_ylabel(\"neurons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e8b295",
   "metadata": {},
   "source": [
    "### Initialise the variational inference model\n",
    "\n",
    "All the inference functions, and the model parameters are contained in the `VAE` class, which contains \n",
    "\n",
    "- All the RNN parameters in: `vae.rnn`\n",
    "    - The dynamics / transition model $p(\\mathbf{z}_t\\mid\\mathbf{z}_{t-1})$ is in: `vae.rnn.transition`\n",
    "    - The observation model $p(\\mathbf{y}_t\\mid\\mathbf{z}_{t})$ is in: `vae.rnn.observation`\n",
    "- If used, the encoder  $e(\\mathbf{z}_t\\mid\\mathbf{y}_{t:t+t'})$ parameters are in `vae.encoder`. Here we will use a CNN encoder (with temporal convolutions and effective window size $t'$)\n",
    "\n",
    "The proposal distribution $r$ from which we sample latents is defined as a combination of the RNN dynamics and the encoder's prediction\n",
    "\n",
    "$$r(\\mathbf{z}_t\\mid\\mathbf{z}_{t-1},\\mathbf{y}_{t:t+t'})\\propto e(\\mathbf{z}_t\\mid\\mathbf{y}_{t:t+t'})p(\\mathbf{z}_t\\mid\\mathbf{z}_{t-1})$$\n",
    "\n",
    "We will here use a one-to-one mapping between RNN units and observations. Note that generally one does not have to do this - if you want to learn a linear map between RNN units / latents and observations set `rnn_params[\"identity_readout\"]` to `False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4cacfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vi_rnn.vae import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d465fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_params = (\n",
    "    {\"kernel_sizes\": [21, 11, 1], # kernel sizes of the CNN\n",
    "    \"padding_mode\": \"constant\", # padding mode of the CNN (e.g., \"circular\", \"constant\", \"reflect\")\n",
    "    \"nonlinearity\": \"gelu\", # \"leaky_relu\" or \"gelu\"\n",
    "    \"n_channels\": [64,64], # number of channels in the CNN (last one will be equal to dim_z)\n",
    "    \"init_scale\": 0.1, # initial scale of the noise predicted by the encoder\n",
    "    \"constant_var\": False, # whether or not to use a constant variance (as opposed to a data-dependent variance)\n",
    "    \"padding_location\": \"acausal\",} # padding location of the CNN (\"causal\", \"acausal\", or \"windowed\")\n",
    ")  \n",
    "rnn_params = {\n",
    "    # noise covariances settings\n",
    "    \"train_noise_z\": True,  # whether or not to train the transition noise scale\n",
    "    \"train_noise_z_t0\": True,  # whether or not to train the initial state noise scale\n",
    "    \"init_noise_z\": 0.1,  # initial scale of the transition noise\n",
    "    \"init_noise_z_t0\": 0.1,  # initial scale of the initial state noise\n",
    "    \"noise_z\": \"diag\",  # transition noise covariance type (\"full\", \"diag\" or \"scalar\"), set to \"full\" when using the optimal proposal\n",
    "    \"noise_z_t0\": \"diag\",  # initial state noise covariance type (\"full\", \"diag\" or \"scalar\"), set to \"full\" when using the optimal proposal\n",
    "    \"transition\": \"low_rank\",\n",
    "    # readout settings\n",
    "    \"observation\": \"one_to_one\",  # if True enforces a one to one mapping between RNN units and recorded units\n",
    "    \"readout_from\": \"currents\",  # set to \"currents\", \"rates\", \"z\" or \"z_and_v\". We can readout from the RNN activity\n",
    "    # before / after applying the non-linearty by setting this to \"currents\" / \"rates\" respectively.\n",
    "    # Alternatively we can directly readout from the latent dynamics z of the RNN by\n",
    "    # setting this to \"z\", or from latents z and input v, by setting this to \"z_and_v\"\n",
    "    \"train_obs_bias\": True,  # whether or not to train a bias term in the observation model\n",
    "    \"train_obs_weights\": True,  # whether or not train the weights of the observation model\n",
    "    \"obs_nonlinearity\": \"softplus\",  # can be used to rectify the output (e.g., when using Poisson observations, use \"softplus\")\n",
    "    \"obs_likelihood\" : \"Poisson\",\n",
    "\n",
    "    # other\n",
    "    \"activation\": \"relu\",  # set the nonlinearity to \"clipped_relu, \"relu\", \"tanh\" or \"identity\"\n",
    "    \"decay\": 0.9,  # initial decay constant, scalar between 0 and 1\n",
    "    \"train_neuron_bias\": True,  # train a bias term for every neuron\n",
    "    \"weight_dist\": \"uniform\",  # weight distribution (\"uniform\" or \"gauss\")\n",
    "    \"initial_state\": \"trainable\",  # initial state (\"trainable\", \"zero\", or \"bias\")\n",
    "    \"simulate_input\": False\n",
    "}\n",
    "\n",
    "\n",
    "VAE_params = {\n",
    "    \"dim_x\": 40,  # observation dimension (number of units in the data)\n",
    "    \"dim_z\": 2,  # latent dimension / rank of the RNN\n",
    "    \"dim_N\": 40,  # amount of units in the RNN (can generally be different then the observation dim)\n",
    "    \"dim_u\": 0,  # input stimulus dimension\n",
    "    \"enc_architecture\": \"CNN\",  # encoder architecture (not trained when using linear Gauss observations)\n",
    "    \"enc_params\": enc_params,  # encoder paramaters\n",
    "    \"rnn_architecture\": \"LRRNN\",  # use a low-rank RNN architecture\n",
    "    \"rnn_params\": rnn_params,  # parameters of the RNN\n",
    "}\n",
    "\n",
    "# initialise the VAE\n",
    "vae = VAE(VAE_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13735937",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "We will now fit an RNN to the data, using the `train_VAE` function. There are two inference functions that can be used during training:\n",
    "- `training_params[\"loss_f\"] = \"opt_smc\"` uses `vae.forward_optimal_proposal()`. This can be used with linear observations and inverts the observation model closed-form.\n",
    "- `training_params[\"loss_f\"] = \"smc\"` uses `vae.forward()`. This can be used for arbitrary observation models, and uses an encoder to update the proposal distribution.\n",
    "\n",
    "Here we use the second as observations model is non-linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0956611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vi_rnn.saving import save_model, load_model\n",
    "from vi_rnn.train import train_VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ef96bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {\n",
    "    \"lr\": 1e-3,  # learning rate start\n",
    "    \"lr_end\": 1e-5,  # learning rate end (with exponential decay)\n",
    "    \"n_epochs\": 1000,  # number of epochs to train\n",
    "    \"grad_norm\": 0,  # gradient clipping above certain norm (if this is set to >0)\n",
    "    \"batch_size\": 10,  # batch size\n",
    "    \"cuda\": False,  # train on GPU\n",
    "    \"k\": 64,  # number of particles to use\n",
    "    \"loss_f\": \"smc\",  # use regular variational SMC (\"smc\"), or use the optimal (\"opt_smc\")\n",
    "    \"resample\": \"systematic\",  # type of resampling \"systematic\", \"multinomial\" or \"none\"\n",
    "    \"run_eval\": False,  # run an evaluation setup during training (requires additional parameters)\n",
    "    \"observation_likelihood\": \"Poisson\",  # \"Gauss\"-ian  or \"Poisson\" observations\n",
    "    \"t_forward\":0, # timesteps to predict without using the encoder\n",
    "    \"sim_v\": False,  # set to True when using time-varying inputs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aa41ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training\n",
    "\n",
    "train_VAE(\n",
    "    vae,\n",
    "    training_params,\n",
    "    dataset,\n",
    "    sync_wandb=False,\n",
    "    out_dir=\"tutorial_data\",\n",
    "    fname=\"tutorial_spikes_new\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we only trained for a couple of epochs we will load a pretrained model\n",
    "# This was trained as above, but for 500 epochs\n",
    "save_model(\n",
    "    vae, training_params, task_params, \"tutorial_data/test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e6e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae, training_params, task_params = load_model(\n",
    "    \"tutorial_data/test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af788d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we only trained for a couple of epochs we will load a pretrained model\n",
    "# This was trained as above, but for 2000 epochs\n",
    "#fname =\"tutorial_data/tutorial_spikes\"\n",
    "#vae, training_params, task_params  = load_model(\n",
    "#   fname, backward_compat=True\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37bec1c",
   "metadata": {},
   "source": [
    "### Plot the trained model's output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02741980",
   "metadata": {},
   "source": [
    "To generate data from our trained model, we can use the `predict` function. We can either use a data-inferred initial state, by passing the data and the argument `initial_state=\"posterior_mean\"` or just sample from the RNNs initial state by passing `initial_state=\"prior_mean\"`.\n",
    "\n",
    "Generally we get nicer visualisation of the latent dynamics by projecting the data on an orthogonalised basis. We here use the basis spanned by the left singular vectors of the RNNs weight matrix, which we obtain using the function `get_orth_proj_latents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7121c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vi_rnn.predict import predict\n",
    "from vi_rnn.utils import get_orth_proj_latents, orthogonalise_network\n",
    "from evaluation.calc_stats import calc_isi_stats,calculate_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c5249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data using our fit model\n",
    "Z_gen, data_gen, rates_gen = predict(\n",
    "    vae,\n",
    "    u=None, # add optional input / stimuli\n",
    "    x=dataset.data_eval,\n",
    "    initial_state=\"posterior_mean\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e4d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = orthogonalise_network(vae)\n",
    "vae.rnn.std_embed_z(vae.rnn.R_z)*torch.mean(vae.rnn.observation.B)/4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e13c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dy = 10\n",
    "dx = 5\n",
    "B = torch.zeros(dy, dx)\n",
    "B[range(dx), range(dx)] = 1\n",
    "B = torch.nn.Parameter(B, requires_grad=True)\n",
    "mask = B\n",
    "cast_B = lambda x: x * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d89ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orthogonalise the latents\n",
    "projection_matrix = get_orth_proj_latents(vae)\n",
    "Z_gen_orth = np.einsum(\"BZT,OZ->BOT\", Z_gen.squeeze(-1), projection_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data generated by our model next to evaluation data\n",
    "# NOTE: we do not expect a timestep wise correspondance, as we are plotting samples from a stochastic\n",
    "# model. Instead we expect the distributions over samples to match.\n",
    "\n",
    "fig, ax = plt.subplots(3)\n",
    "\n",
    "ax[0].set_ylabel(\"Observed activity\")\n",
    "ax[0].imshow(dataset.data_eval[:,:1000],aspect='auto',cmap=\"Grays\",vmax=2)\n",
    "\n",
    "ax[1].set_ylabel(\"Generated activity\")\n",
    "ax[1].imshow(data_gen[0],aspect='auto',cmap=\"Grays\",vmax=2)\n",
    "\n",
    "\n",
    "ax[2].set_ylabel(\"Generated latents\")\n",
    "ax[2].plot(Z_gen_orth[0].T)\n",
    "ax[2].set_xlabel(\"timesteps\")\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.set_xlim(0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f21ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate some statistics to compare the true and generated data\n",
    "\n",
    "spikes_GT = dataset.data_eval.T.detach().numpy()\n",
    "spikes_gen = data_gen[0,:,:,0].T.detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(3, 1))\n",
    "\n",
    "# CV and ISI\n",
    "bins = np.linspace(0, 100, 100)\n",
    "CVs_isi_gen, Means_isi_gen, Std_isi_gen = calc_isi_stats(spikes_gen)\n",
    "CVs_isi_GT, Means_isi_GT, Std_isi_GT = calc_isi_stats(spikes_GT)\n",
    "Means_gen = np.mean(spikes_gen, axis=0)\n",
    "Means_GT = np.mean(spikes_GT, axis=0)\n",
    "\n",
    "\n",
    "ax[0].set_ylabel(\"Generated\")\n",
    "ax[0].set_xlabel(\"Data\")\n",
    "\n",
    "ax[1].scatter(Means_isi_GT, Means_isi_gen, color=\"teal\", alpha=0.7, s=20, linewidth=0)\n",
    "ax[1].set_title(\"mean ISIs\")\n",
    "max = np.max([Means_isi_GT, Means_isi_gen]) * 1.1\n",
    "ax[1].plot([0, max], [0, max], color=\"grey\", linestyle=\"--\", zorder=-1000)\n",
    "ax[1].set_aspect(1)\n",
    "\n",
    "ax[0].scatter(Means_GT, Means_gen, color=\"teal\", alpha=0.7, s=20, linewidth=0)\n",
    "ax[0].set_title(\"mean rates\")\n",
    "max = np.max([Means_gen, Means_GT]) * 1.1\n",
    "ax[0].plot([0, max], [0, max], color=\"grey\", linestyle=\"--\", zorder=-1000)\n",
    "ax[0].set_aspect(1)\n",
    "\n",
    "ax[0].set_yscale(\"log\")\n",
    "ax[0].set_xscale(\"log\")\n",
    "ax[0].set_xticks([0.1, 0.3])\n",
    "ax[0].set_yticks([0.1, 0.3])\n",
    "ax[1].set_xlim(0)\n",
    "ax[1].set_ylim(0)\n",
    "\n",
    "# format axis\n",
    "ax[0].yaxis.set_major_formatter(StrMethodFormatter(\"{x:.1f}\"))\n",
    "ax[0].yaxis.set_minor_formatter(NullFormatter())\n",
    "ax[0].xaxis.set_major_formatter(StrMethodFormatter(\"{x:.1f}\"))\n",
    "ax[0].xaxis.set_minor_formatter(NullFormatter())\n",
    "ax[0].set_yticklabels([])\n",
    "ax[1].set_yticklabels([])\n",
    "\n",
    "# Plot pairwise correlations\n",
    "correlation_GT = calculate_correlation(spikes_GT)\n",
    "correlation_gen = calculate_correlation(spikes_gen)\n",
    "\n",
    "i_upper = np.triu_indices(40, k=1)\n",
    "corr_values_GT = correlation_GT[i_upper]\n",
    "corr_values_gen = correlation_gen[i_upper]\n",
    "\n",
    "ax[2].scatter(\n",
    "   corr_values_GT, corr_values_gen, color=\"teal\", alpha=0.2, linewidth=0, s=10\n",
    ")\n",
    "ax[2].set_aspect(1)\n",
    "\n",
    "ax[2].set_title(\"pairwise correlations\")\n",
    "ax[2].set_yticklabels([])\n",
    "max = np.max([corr_values_GT, corr_values_gen]) * 1.1\n",
    "ax[2].plot([0, max], [0, max], color=\"grey\", linestyle=\"--\", zorder=-10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620237b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smc_rnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
