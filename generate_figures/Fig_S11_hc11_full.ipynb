{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "file_dir = os.getcwd()\n",
    "sys.path.append(file_dir + \"/../\")\n",
    "import torch\n",
    "import numpy as np\n",
    "from vi_rnn.saving import load_model\n",
    "from scipy.signal import welch\n",
    "from evaluation.calc_stats import calc_isi_stats, calculate_correlation\n",
    "from vi_rnn.saving import load_model\n",
    "from vi_rnn.utils import get_orth_proj_latents\n",
    "from scipy.signal import welch\n",
    "from scipy.signal.windows import hann\n",
    "from scipy.stats import zscore\n",
    "from scipy import signal, ndimage\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# we are using data from: https://crcns.org/data-sets/hc/hc-11/about-hc-11\n",
    "# Grosmark, A.D., and Buzsáki, G. (2016). Diversity in neural firing dynamics supports both rigid and learned hippocampal sequences. Science 351, 1440–1443.\n",
    "# Chen, Z., Grosmark, A.D., Penagos, H., and Wilson, M.A. (2016). Uncovering representations of sleep-associated hippocampal ensemble spike activity. Sci. Rep. 6, 32193."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "fs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../models/hpc11/_CNN_causal_PLRNN_Z_Date_122024_06_24_T_17_54_22\"\n",
    "vae, params, task_params, training_params = load_model(str(filename))\n",
    "rank = vae.dim_z\n",
    "print(rank)\n",
    "vae = vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spiking data\n",
    "train_data = np.load(\"../data_untracked/train_hpc_11_i25.npy\")\n",
    "test_data = np.load(\"../data_untracked/test_hpc_11_i25.npy\")\n",
    "dim_x, T = test_data.shape\n",
    "_, T_train = train_data.shape\n",
    "print(\"Spiking train data shape: \", train_data.shape)\n",
    "print(\"Spiking test data shape: \", test_data.shape)\n",
    "# load locations\n",
    "test_locs = np.load(\"../data_untracked/testloc.npy\")\n",
    "train_locs = np.load(\"../data_untracked/trainloc.npy\")\n",
    "print(\"Locations test shape: \", test_locs.shape)\n",
    "print(\"Locations train shape: \", train_locs.shape)\n",
    "\n",
    "# load lfp\n",
    "lfp_run = np.load(\"../data_untracked/run_maze.npy\").T\n",
    "print(\"LFP run shape: \", lfp_run.shape)\n",
    "lfp_norun = np.load(\"../data_untracked/norun_maze.npy\").T\n",
    "print(\"LFP norun shape: \", lfp_norun.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.rnn.get_initial_state(torch.zeros(1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the trained network\n",
    "\n",
    "# get model learned initial state\n",
    "z0 = vae.rnn.get_initial_state(torch.zeros(1,0))\n",
    "# get latent trajectory (cut first 1000 time steps)\n",
    "Z = vae.rnn.get_latent_time_series(time_steps=T, cut_off=1000, z0=z0, noise_scale=1)\n",
    "\n",
    "# get spikes\n",
    "lam = vae.rnn.get_observation(Z, noise_scale=0)[0, :, :, 0]\n",
    "spikes_pred = torch.poisson(lam).T.detach().numpy()\n",
    "\n",
    "# project latents on orthogonalised connnectivity\n",
    "projection_matrix = get_orth_proj_latents(vae)\n",
    "Z = projection_matrix @ Z[0, :, :, 0]\n",
    "prior_Z = Z.detach().numpy()\n",
    "\n",
    "\n",
    "# get posterior latents given test\n",
    "k = 128  # number of particles\n",
    "with torch.no_grad():\n",
    "    Qzs_filt_avg, Qzs_sm_avg, Xs_filt_avg, Xs_sm_avg = vae.predict_NLB(\n",
    "        torch.from_numpy(test_data).float().unsqueeze(0),\n",
    "        u=None,\n",
    "        k=k,\n",
    "        t_held_in=T,\n",
    "        t_forward=0,\n",
    "        marginal_smoothing=False,\n",
    "    )\n",
    "Qzs_filt_avg = Qzs_filt_avg[0].mean(axis=-1)  # average over particles\n",
    "Qzs_filt_avg = projection_matrix @ Qzs_filt_avg\n",
    "post_Z = Qzs_filt_avg.detach().numpy()\n",
    "\n",
    "# get posterior latents given train\n",
    "k = 128  # number of particles\n",
    "with torch.no_grad():\n",
    "    Qzs_filt_avg, Qzs_sm_avg, Xs_filt_avg, Xs_sm_avg = vae.predict_NLB(\n",
    "        torch.from_numpy(train_data).float().unsqueeze(0),\n",
    "        u=None,\n",
    "        k=k,\n",
    "        t_held_in=T_train,\n",
    "        t_forward=0,\n",
    "        marginal_smoothing=False,\n",
    "    )\n",
    "Qzs_filt_avg = Qzs_filt_avg[0].mean(axis=-1)  # average over particles\n",
    "Qzs_filt_avg = projection_matrix @ Qzs_filt_avg\n",
    "post_Z_train = Qzs_filt_avg.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "prior_Z = zscore(prior_Z, axis=1)\n",
    "post_Z = zscore(post_Z, axis=1)\n",
    "post_Z_train = zscore(post_Z_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zscore the lfp and get the power spectral density\n",
    "lfp_run_pr = zscore(lfp_run, axis=1).mean(axis=0)\n",
    "lfp_norun_pr = zscore(lfp_norun, axis=1).mean(axis=0)\n",
    "\n",
    "nperseg = 1024\n",
    "\n",
    "f_lfp_run, psd_lfp_run = welch(lfp_run_pr, fs=fs, nperseg=nperseg)\n",
    "f_lfp_norun, psd_lfp_norun = welch(lfp_norun_pr, fs=fs, nperseg=nperseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain power spectral density of the prior latents\n",
    "\n",
    "nperseg = 400\n",
    "\n",
    "f_pZ1, psd_pZ1 = welch(prior_Z[0], fs=fs, nperseg=nperseg)\n",
    "f_pZ2, psd_pZ2 = welch(prior_Z[1], fs=fs, nperseg=nperseg)\n",
    "f_pZ3, psd_pZ3 = welch(prior_Z[2], fs=fs, nperseg=nperseg)\n",
    "f_pZ4, psd_pZ4 = welch(prior_Z[3], fs=fs, nperseg=nperseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression from latents to LFP\n",
    "\n",
    "# Define the model and fit it\n",
    "model = Ridge()\n",
    "\n",
    "X = post_Z_train.T\n",
    "X_test = post_Z.T  #\n",
    "X_prior = prior_Z.T\n",
    "\n",
    "# Smooth latents\n",
    "window_l = 301\n",
    "window = hann(window_l)\n",
    "X = ndimage.convolve1d(X, window, axis=0)\n",
    "X_test = ndimage.convolve1d(X_test, window, axis=0)\n",
    "X_prior = ndimage.convolve1d(X_prior, window, axis=0)\n",
    "\n",
    "\n",
    "# fit model\n",
    "y = train_locs\n",
    "model.fit(X, y)\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_train = model.predict(X)\n",
    "y_prior = model.predict(X_prior)\n",
    "r2 = model.score(X_test, test_locs)\n",
    "\n",
    "print(\"R2 score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pr = np.arange(0, len(y_prior)) / 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted vs rat\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(1.5, 1))\n",
    "pr = \"#9BB5DE\"\n",
    "rat = \"#2B3073\"\n",
    "dur = 20 * 40\n",
    "ax.plot(t_pr, y_pred, color=pr, alpha=0.7, label=\"predicted\")\n",
    "ax.plot(t_pr, test_locs, color=rat, alpha=0.7, label=\"rat\")\n",
    "legend_labels = [\"predicted\", \"rat\"]\n",
    "legend_colors = [pr, rat]\n",
    "legend = plt.legend(\n",
    "    legend_labels,\n",
    "    handletextpad=0,\n",
    "    handlelength=0,\n",
    "    fancybox=True,\n",
    "    loc=\"upper right\",\n",
    "    bbox_to_anchor=(1.12, 0.6),\n",
    ")\n",
    "for text, color in zip(legend.get_texts(), legend_colors):\n",
    "    text.set_color(color)\n",
    "ax.set_xlabel(\"time (s)\")\n",
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = abs(ndimage.convolve1d(np.gradient(y_prior), window)) > 1  # 0.75\n",
    "print(\"percentage running\", np.sum(inds) / len(inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LFPs\n",
    "\n",
    "nperseg = 400\n",
    "color1 = \"teal\"\n",
    "color2 = \"#A860AF\"\n",
    "mean_psd_run = []\n",
    "mean_psd_stat = []\n",
    "for i in range(len(prior_Z)):\n",
    "    f_pZ, psd_pZ = welch(prior_Z[i, inds], fs=fs, nperseg=nperseg)\n",
    "    mean_psd_run.append(psd_pZ)\n",
    "    f_pZ, psd_pZ = welch(prior_Z[i, ~inds], fs=fs, nperseg=nperseg)\n",
    "    mean_psd_stat.append(psd_pZ)\n",
    "mean_psd_run = np.array(mean_psd_run).mean(axis=0)\n",
    "mean_psd_stat = np.array(mean_psd_stat).mean(axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "(line1,) = ax.semilogy(\n",
    "    f_pZ, mean_psd_run, alpha=0.9, zorder=0, label=\"running\", color=color1\n",
    ")\n",
    "\n",
    "(line2,) = ax.semilogy(\n",
    "    f_pZ, mean_psd_stat, alpha=0.9, zorder=0, label=\"stationary\", color=color2\n",
    ")\n",
    "(line3,) = ax.semilogy(\n",
    "    f_lfp_run, psd_lfp_run, color=\"black\", alpha=0.6, zorder=0, label=\"LFP\"\n",
    ")\n",
    "(line4,) = ax.semilogy(\n",
    "    f_lfp_norun, psd_lfp_norun, color=\"grey\", alpha=0.6, zorder=0, label=\"LFP\"\n",
    ")\n",
    "ax.set_xlim([0, 20])\n",
    "ax.set_ylim([10**-4, 1])\n",
    "ax.set_title(\"psd\")\n",
    "ax.set_xlabel(\"frequency (hz)\")\n",
    "ax.tick_params(axis=\"y\", which=\"both\", width=1)\n",
    "\n",
    "ax.set_yticks([0.001, 0.1])\n",
    "ax.set_yticklabels([\"0.001\", \"0.1\"])\n",
    "ax.set_xticks([0.2, 10, 20])\n",
    "# custom legend handles. note: legends were manually adjusted using illustrator afterwards to include the LFP signal\n",
    "legend_labels = [\"run\", \"stat\", \"$LFP run$\", \"$LFP stat$\"]\n",
    "\n",
    "legend_colors = [color1, color2, \"black\", \"grey\"]\n",
    "\n",
    "legend = ax.legend(\n",
    "    legend_labels,\n",
    "    handletextpad=0,\n",
    "    handlelength=0,\n",
    "    fancybox=True,\n",
    "    loc=\"upper right\",\n",
    "    bbox_to_anchor=(1, 1),\n",
    ")\n",
    "for text, color in zip(legend.get_texts(), legend_colors):\n",
    "    text.set_color(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get firing rates\n",
    "fr_test = np.mean(test_data, axis=1) * fs\n",
    "fr_train = np.mean(train_data, axis=1) * fs\n",
    "fr_gen = np.mean(spikes_pred, axis=0) * fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrices\n",
    "test_correlation = calculate_correlation(test_data.T)\n",
    "gen_correlation = calculate_correlation(spikes_pred)\n",
    "train_correlation = calculate_correlation(train_data.T)\n",
    "\n",
    "# Extracting upper triangle values without the diagonal\n",
    "i_upper = np.triu_indices(dim_x, k=1)\n",
    "test_corr_values = test_correlation[i_upper]\n",
    "gen_corr_values = gen_correlation[i_upper]\n",
    "train_corr_values = train_correlation[i_upper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ISI stats\n",
    "\n",
    "CVs_isi_test, Means_isi_test, Std_isi_test = calc_isi_stats(test_data.T, dt=1 / fs)\n",
    "CVs_isi_gen, Means_isi_gen, Std_isi_gen = calc_isi_stats(spikes_pred, dt=1 / fs)\n",
    "CVs_isi_train, Means_isi_train, Std_isi_train = calc_isi_stats(train_data.T, dt=1 / fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plots\n",
    "\n",
    "color1 = \"#7B46C1\"\n",
    "color2 = \"#A860AF\"\n",
    "color3 = \"#7C277D\"\n",
    "color4 = \"#8A44A4\"\n",
    "colors = [\n",
    "    color1,\n",
    "    color2,\n",
    "    color3,\n",
    "    color4,\n",
    "    color1,\n",
    "    color2,\n",
    "    color3,\n",
    "    color4,\n",
    "    color1,\n",
    "    color2,\n",
    "    color3,\n",
    "    color4,\n",
    "    color1,\n",
    "    color2,\n",
    "    color3,\n",
    "    color4,\n",
    "]\n",
    "\n",
    "tg = \"teal\"\n",
    "tr = \"firebrick\"\n",
    "cmap = plt.get_cmap(\"tab20b\")\n",
    "cmap2 = plt.get_cmap(\"Dark2\")\n",
    "\n",
    "with mpl.rc_context(fname=\"matplotlibrc\"):\n",
    "\n",
    "    # Create a figure with specified size\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(6, 3))\n",
    "    fig.subplots_adjust(hspace=0.2, wspace=0.6)\n",
    "\n",
    "    ax1 = axes[0, 0]\n",
    "    ax2 = axes[0, 2]\n",
    "    ax3 = axes[0, 1]\n",
    "    ax4 = axes[1, 0]\n",
    "    ax5 = axes[1, 1]\n",
    "    ax6 = axes[1, 2]\n",
    "    ax7 = axes[1, 3]\n",
    "    ax8 = axes[0, 3]\n",
    "\n",
    "    # extract the width gap\n",
    "    gap = ax5.get_position().x0 - ax4.get_position().x1\n",
    "\n",
    "    # manually adjust the locations of wider plots\n",
    "    width_scaling_factor = 1.6\n",
    "    new_positions = []\n",
    "\n",
    "    for i, ax in enumerate(axes[0, :3]):\n",
    "        pos = ax.get_position()\n",
    "        if i == 0:\n",
    "            new_positions.append(\n",
    "                [pos.x0, pos.y0, pos.width * width_scaling_factor, pos.height]\n",
    "            )\n",
    "        else:\n",
    "            new_positions.append(\n",
    "                [\n",
    "                    new_positions[i - 1][0] + new_positions[i - 1][2] + gap * 4 / 2.1,\n",
    "                    pos.y0,\n",
    "                    pos.width * width_scaling_factor,\n",
    "                    pos.height,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    for i, ax in enumerate(axes[0, :3]):\n",
    "        ax.set_position(new_positions[i])\n",
    "    sec = 20\n",
    "    init = 750\n",
    "    duration = sec * 40\n",
    "    # data prediction\n",
    "    pr = \"#9BB5DE\"\n",
    "    rat = \"#2B3073\"\n",
    "    ax1.plot(t_pr, y_pred, color=pr, alpha=0.7, label=\"predicted\")\n",
    "    ax1.plot(t_pr, test_locs, color=rat, alpha=0.7, label=\"rat\")\n",
    "    legend_labels = [\"predicted\", \"rat\"]\n",
    "    legend_colors = [pr, rat]\n",
    "    legend = plt.legend(\n",
    "        legend_labels,\n",
    "        handletextpad=0,\n",
    "        handlelength=0,\n",
    "        fancybox=True,\n",
    "        loc=\"upper right\",\n",
    "        bbox_to_anchor=(1.12, 0.6),\n",
    "    )\n",
    "    for text, color in zip(legend.get_texts(), legend_colors):\n",
    "        text.set_color(color)\n",
    "    ax1.set_xlabel(\"time (s)\")\n",
    "    ax1.set_xlim(0,t_pr[-1])\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_title(\"predicted location\")\n",
    "    # generated spikes\n",
    "\n",
    "    ax3.set_title(\"generated location\")\n",
    "    ax3.plot(t_pr, y_prior, color=pr, alpha=1)\n",
    "    ax3.set_xlabel(\"time (s)\")\n",
    "    ax3.set_yticks([])\n",
    "    ax3.set_xlim(0,t_pr[-1])\n",
    "\n",
    "    # latents\n",
    "    t = np.linspace(0, sec, duration)\n",
    "    for i in range(len(prior_Z)):\n",
    "        ax2.plot(\n",
    "            t,\n",
    "            prior_Z[i][init : init + duration] + (i - 1) * 3,\n",
    "            alpha=0.9,\n",
    "            # label=f\"Z{i}\",\n",
    "            color=colors[i],\n",
    "        )\n",
    "\n",
    "    ax2.set_xlim(0, sec)\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_xticks([0, 10, 20])\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_xlabel(\"time (s)\")\n",
    "    ax2.set_title(\"latents\")\n",
    "\n",
    "    # coefficient of variation\n",
    "    n_dots = len(CVs_isi_test)\n",
    "    zorders = np.arange(n_dots * 2)\n",
    "    np.random.shuffle(zorders)\n",
    "    for i in range(n_dots):\n",
    "        ax5.scatter(\n",
    "            CVs_isi_test[i],\n",
    "            CVs_isi_gen[i],\n",
    "            s=10,\n",
    "            alpha=0.7,\n",
    "            color=tg,\n",
    "            zorder=zorders[i],\n",
    "        )\n",
    "        ax5.scatter(\n",
    "            CVs_isi_test[i],\n",
    "            CVs_isi_train[i],\n",
    "            s=10,\n",
    "            alpha=0.7,\n",
    "            color=tr,\n",
    "            label=\"train\",\n",
    "            zorder=zorders[i + n_dots],\n",
    "        )\n",
    "\n",
    "    ax5.plot([0, 4], [0, 4], color=\"gray\", linestyle=\"--\", zorder=0)\n",
    "    ax5.set_title(\"cv ISIs\")\n",
    "    ax5.set_xticks([0, 4])\n",
    "    ax5.set_yticks([0, 4])\n",
    "    ax5.set_xlabel(\"test\")\n",
    "    ax5.set_xlim([0, 4])\n",
    "    ax5.set_ylim([0, 4])\n",
    "\n",
    "    # mean rates\n",
    "    ax4.plot(\n",
    "        np.linspace(0, 5, 2),\n",
    "        np.linspace(0, 5, 2),\n",
    "        color=\"gray\",\n",
    "        linestyle=\"--\",\n",
    "        zorder=0,\n",
    "    )\n",
    "    n_dots = len(fr_test)\n",
    "    zorders = np.arange(n_dots * 2)\n",
    "    np.random.shuffle(zorders)\n",
    "    for i in range(n_dots):\n",
    "        ax4.scatter(fr_test[i], fr_gen[i], s=10, alpha=0.7, color=tg, zorder=zorders[i])\n",
    "        ax4.scatter(\n",
    "            fr_test[i],\n",
    "            fr_train[i],\n",
    "            s=10,\n",
    "            alpha=0.7,\n",
    "            color=tr,\n",
    "            zorder=zorders[i + n_dots],\n",
    "        )\n",
    "\n",
    "    ax4.set_title(\"mean rates (hz)\")\n",
    "    ax4.set_xticks([1, 5])\n",
    "    ax4.set_yticks([1, 5])\n",
    "    ax4.set_xlabel(\"test\")\n",
    "    ax4.set_ylabel(\"gen / train\")\n",
    "\n",
    "    # custom legend labels and colors\n",
    "    legend_labels = [\"test/gen\", \"test/train\"]\n",
    "    legend_colors = [tg, tr]\n",
    "\n",
    "    # add custom legend\n",
    "    legend_elements = [\n",
    "        plt.Line2D([0], [0], color=color, lw=0, label=label)\n",
    "        for color, label in zip(legend_colors, legend_labels)\n",
    "    ]\n",
    "    legend = ax4.legend(\n",
    "        handles=legend_elements,\n",
    "        handletextpad=0,\n",
    "        handlelength=0,\n",
    "        fancybox=True,\n",
    "        loc=\"upper right\",\n",
    "        bbox_to_anchor=(1.16, 0.45),\n",
    "        fontsize=6,\n",
    "    )\n",
    "\n",
    "    for text, color in zip(legend.get_texts(), legend_colors):\n",
    "        text.set_color(color)\n",
    "\n",
    "    # pairwise correlation\n",
    "    ax6.plot([-0.1, 0.2], [-0.1, 0.2], color=\"gray\", linestyle=\"--\", zorder=0)\n",
    "    dots = len(test_corr_values)\n",
    "    zorders = np.arange(n_dots * 2)\n",
    "    np.random.shuffle(zorders)\n",
    "    for i in range(n_dots):\n",
    "        ax6.scatter(\n",
    "            test_corr_values[i],\n",
    "            gen_corr_values[i],\n",
    "            s=10,\n",
    "            alpha=0.7,\n",
    "            color=tg,\n",
    "            zorder=zorders[i],\n",
    "        )\n",
    "        ax6.scatter(\n",
    "            test_corr_values[i],\n",
    "            train_corr_values[i],\n",
    "            s=10,\n",
    "            alpha=0.7,\n",
    "            color=tr,\n",
    "            label=\"train\",\n",
    "            zorder=zorders[i + n_dots],\n",
    "        )\n",
    "\n",
    "    ax6.tick_params(axis=\"x\", which=\"both\", width=1)\n",
    "    ax6.tick_params(axis=\"y\", which=\"both\", width=1)\n",
    "    ax6.set_title(\"pairwise corr.\")\n",
    "    ax6.set_xlabel(\"test\")\n",
    "    ax6.set_yticks([-0.1, 0.2])\n",
    "    ax6.set_yticklabels([\"-0.1\", \"0.2\"])\n",
    "    ax6.set_xticks([-0.1, 0.2])\n",
    "    ax6.set_xticklabels([\"-0.1\", \"0.2\"])\n",
    "    ax6.set_xlim([-0.1, 0.2])\n",
    "    ax6.set_ylim([-0.1, 0.2])\n",
    "\n",
    "    # PSD\n",
    "    color1 = \"#7B46C1\"\n",
    "    color2 = \"hotpink\"\n",
    "    color3 = \"teal\"\n",
    "    color4 = \"lightblue\"\n",
    "    (line1,) = ax7.semilogy(\n",
    "        f_pZ, mean_psd_run, alpha=0.9, zorder=10, label=\"running\", color=color1\n",
    "    )\n",
    "\n",
    "    # Plot stationary PS\n",
    "    (line2,) = ax7.semilogy(\n",
    "        f_pZ, mean_psd_stat, alpha=0.9, zorder=0, label=\"stationary\", color=color2\n",
    "    )\n",
    "\n",
    "    (line3,) = ax7.semilogy(\n",
    "        f_lfp_run, psd_lfp_run, color=color3, alpha=1, zorder=3, label=\"LFP\"\n",
    "    )\n",
    "    (line4,) = ax7.semilogy(\n",
    "        f_lfp_norun, psd_lfp_norun, color=color4, alpha=1, zorder=4, label=\"LFP norun\"\n",
    "    )\n",
    "    ax7.set_xlim([0, 20])\n",
    "    ax7.set_ylim([10**-4, 1])\n",
    "    ax7.set_title(\"psd\")\n",
    "    ax7.set_xlabel(\"frequency (hz)\")\n",
    "    ax7.tick_params(axis=\"y\", which=\"both\", width=1)\n",
    "\n",
    "    ax7.set_yticks([0.001, 0.1])\n",
    "    ax7.set_yticklabels([\"0.001\", \"0.1\"])\n",
    "    ax7.set_xticks([0.2, 10, 20])\n",
    "\n",
    "    legend_labels = [\n",
    "        \"model running\",\n",
    "        \"model static\",\n",
    "        \"LFP rat running\",\n",
    "        \"LFP rat static\",\n",
    "    ]\n",
    "\n",
    "    legend_colors = [color1, color2, color3, color4]\n",
    "\n",
    "    legend = ax7.legend(\n",
    "        legend_labels,\n",
    "        handletextpad=0,\n",
    "        handlelength=0,\n",
    "        fancybox=True,\n",
    "        loc=\"upper right\",\n",
    "        bbox_to_anchor=(2, 1),\n",
    "    )\n",
    "    for text, color in zip(legend.get_texts(), legend_colors):\n",
    "        text.set_color(color)\n",
    "\n",
    "    ax8.axis(\"off\")\n",
    "    plt.gcf().set_size_inches(5.2, 3)\n",
    "\n",
    "    ax1.set_box_aspect(0.625)\n",
    "    ax2.set_box_aspect(0.625)\n",
    "    ax3.set_box_aspect(0.625)\n",
    "    ax7.set_box_aspect(1)\n",
    "    ax4.set_box_aspect(1)\n",
    "    ax5.set_box_aspect(1)\n",
    "    ax6.set_box_aspect(1)\n",
    "    ax8.set_box_aspect(1)\n",
    "\n",
    "    plt.savefig(\"../figures/hpc11_full.png\", dpi=300)\n",
    "    plt.savefig(\"../figures/hpc11_full.pdf\", dpi=300)\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurips",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
